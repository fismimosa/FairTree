{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__5HSjfCQKpx"
   },
   "outputs": [],
   "source": [
    "# Global Config Variables\n",
    "n0 = 1000  # number of p=0 points in metric space\n",
    "V = n0  # Threshold for p=0\n",
    "#K = 10# No of clusters\n",
    "A= 5# No of attributes\n",
    "J =2 #or 3 no of demographic group values\n",
    "iterations = 1  # maximum iteration in clustering OE\n",
    "runs =10\n",
    "option='Kmeans'\n",
    "dataset='Adult'\n",
    "\n",
    "p_j = [53.52,26.40]  #each can be max of p % in dataset   This will be \\tau_i * k vector \n",
    "#[48.512,22.512,8.968]  0.2\n",
    "# [53.536,26.463]    0.8  adult\n",
    "#[25,12]   adult\n",
    "#[13.384,6.6158] adult 0.2\n",
    "#[25,10,4]  Bank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MtjR8kAQKp3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import log2\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "import timeit\n",
    "import numba\n",
    "from numba import jit , njit\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "def load_Bank(data_dir=''):\n",
    "\n",
    "    data_dir = data_dir\n",
    "    _path = 'bank-full_p_6col.csv'\n",
    "    data_path = os.path.join(data_dir, _path)\n",
    "\n",
    "    K = 10\n",
    "\n",
    "    df = pandas.read_csv(data_path, sep=',')\n",
    "    #print(df.head())\n",
    "    #print(len(df))\n",
    "    \n",
    "    return df\n",
    "#load_Bank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlxXl2qOQKp7",
    "outputId": "594cd579-bac8-4830-edac-b5d8de683349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hpc128/Downloads/Fresh Experiments-Again/tau\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "def load_Adult(data_dir=''):\n",
    "\n",
    "    data_dir = data_dir\n",
    "    _path = 'adult_p.csv'\n",
    "    data_path = os.path.join(data_dir, _path)\n",
    "\n",
    "    K = 10\n",
    "\n",
    "    df = pandas.read_csv(data_path, sep=',')\n",
    "    #print(df.head())\n",
    "    #print(len(df))\n",
    "    \n",
    "    return df\n",
    "#load_Adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjN95fmjQKp_",
    "outputId": "eea7f3a6-613d-49b0-dddd-0ff95b89c6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32561\n",
      "32561\n",
      "0.6692054912318418\n",
      "0.33079450876815825\n",
      "21790\n",
      "10771\n"
     ]
    }
   ],
   "source": [
    "if dataset=='Adult'\n",
    "    df=load_Adult()\n",
    "    df= df.round(decimals=5)\n",
    "    print(len(df))\n",
    "    df = df.dropna()\n",
    "    print(len(df))\n",
    "    typ = df['gender'].values\n",
    "    c1 = np.count_nonzero(typ == 0)\n",
    "    c2 = np.count_nonzero(typ == 1)\n",
    "    \n",
    "    n_j=[c1,c2]\n",
    "\n",
    "    print(c1/(c1+c2))\n",
    "    print(c2/(c1+c2))\n",
    "\n",
    "    print(c1)\n",
    "    print(c2)\n",
    "elif dataset=='Bank':\n",
    "    df=load_Bank()\n",
    "    df= df.round(decimals=5)\n",
    "    print(len(df))\n",
    "    df = df.dropna()\n",
    "    print(len(df))\n",
    "    df['type'] = df['type']-1\n",
    "    typ = df['type'].values\n",
    "    #print(len(typ))\n",
    "    #print(df.head(10))\n",
    "    c1 = np.count_nonzero(typ == 0)\n",
    "    c2 = np.count_nonzero(typ == 1)\n",
    "    c3 = np.count_nonzero(typ == 2)\n",
    "    n_j=[c1,c2,c3]\n",
    "\n",
    "    print(c1/(c1+c2+c3))\n",
    "    print(c2/(c1+c2+c3))\n",
    "    print(c3/(c1+c2+c3))\n",
    "\n",
    "\n",
    "    print(c1)\n",
    "    print(c2)\n",
    "    print(c3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DK1GKCUQKqC"
   },
   "outputs": [],
   "source": [
    "def dual_print(f,*args,**kwargs):\n",
    "    #print(*args,**kwargs)\n",
    "    print(*args,**kwargs,file=f)\n",
    "\n",
    "def load_dataset(csv_name):\n",
    "    # read the dataset from csv_name and return as pandas dataframe\n",
    "    df = pd.read_csv(csv_name, header=None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def k_random_index(df,K):\n",
    "    # return k random indexes in range of dataframe\n",
    "    return random.sample(range(0, len(df)), K)\n",
    "\n",
    "def find_k_initial_centroid(df,K):\n",
    "    centroids = []    # make of form [ [x1,y1]....]\n",
    "\n",
    "    rnd_idx = k_random_index(df,K)\n",
    "  \n",
    "    for i in rnd_idx:\n",
    "        coordinates =[]\n",
    "        for a in range(0,A):\n",
    "            coordinates.append(df.loc[i][a])\n",
    "        centroids.append(coordinates)   #df is X,Y,....., Type\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def find_k_initial_centroid_old(df):\n",
    "    centroids = []    # make of form [ [x1,y1]....]\n",
    "\n",
    "    rnd_idx = k_random_index(df)\n",
    "    #print(rnd_idx)\n",
    "    for i in rnd_idx:\n",
    "        coordinates =[]\n",
    "        for a in range(0,A):\n",
    "            coordinates.append(df.loc[i][a])\n",
    "        centroids.append(coordinates)   #df is X,Y,....., Type\n",
    "\n",
    "    return centroids\n",
    "\n",
    "#nOt using\n",
    "def calc_distance(x1, y1, x2, y2):\n",
    "    # returns the euclidean distance between two points\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5\n",
    "\n",
    "def calc_distance_a(centroid, point):\n",
    "   \n",
    "\n",
    "    sum_ = 0\n",
    "\n",
    "    for i in range(0, len(centroid)):\n",
    "        sum_ = sum_ + (centroid[i]-point[i])**2\n",
    "\n",
    "    return sum_ #**0.5\n",
    "@njit(parallel=False)\n",
    "def find_distances_fast(k_centroids, df):\n",
    "    \n",
    "  \n",
    "    dist = np.zeros((len(k_centroids),len(df),A+2),np.float64)\n",
    "    Kcnt = 0 \n",
    "    for c in k_centroids:  #K-centroid is of form [ c1=[x1,y1.....z1], c2=[x2,y2....z2].....]\n",
    "       \n",
    "        l = np.zeros((len(df),A+2),np.float64)\n",
    "        \n",
    "     \n",
    "        index = 0 \n",
    "        for row in df:                # row is now x,y,z......type\n",
    "            # append all coordinates to point\n",
    "            dis = np.sum((c- row[:A])**2)#calc_distance_a(c, point)\n",
    "            #Processing the vector for list\n",
    "            row_list = np.array([dis])\n",
    "            #append distance or l norm\n",
    "            row_list = np.append(row_list,row[:A+1])\n",
    "            #append all coordinates #append type of this row\n",
    "  \n",
    "            l[index] = row_list\n",
    "            index = index + 1\n",
    "            #l.append([calc_distance(c[0], c[1], row[0], row[1]), row[0], row[1], row[2]])  # [dist, X, Y,....Z , type]\n",
    "            # l contains list of type [dist,X,Y.....,Z,type] for each points in metric space\n",
    "        dist[Kcnt]= l\n",
    "        Kcnt = Kcnt + 1\n",
    "\n",
    "    # return dist which contains distances of all points from every centroid\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def find_distances(k_centroids, df):\n",
    "    dist = []\n",
    "    for c in k_centroids:  #K-centroid is of form [ c1=[x1,y1.....z1], c2=[x2,y2....z2].....]\n",
    "        l = []\n",
    "      \n",
    "\n",
    "        for index, row in df.iterrows():                # row is now x,y,z......type\n",
    "            point =[]\n",
    "            for a in range(0, A):\n",
    "                point.append(row.iloc[a])  # append all coordinates\n",
    "\n",
    "            dis = calc_distance_a(c, point)\n",
    "            #Processing the vector for list\n",
    "            row_list = [dis]\n",
    "            #append distance or l norm\n",
    "\n",
    "            for a in range(0, A):\n",
    "                row_list.append(row.iloc[a])   #append all coordinates\n",
    "            #print(row.iloc[a+1])\n",
    "            row_list.append(row.iloc[a+1])   #append type of this row\n",
    "\n",
    "            l.append(row_list)\n",
    "            #l.append([calc_distance(c[0], c[1], row[0], row[1]), row[0], row[1], row[2]])  # [dist, X, Y,....Z , type]\n",
    "            # l contains list of type [dist,X,Y.....,Z,type] for each points in metric space\n",
    "        dist.append(l)\n",
    "\n",
    "    # return dist which contains distances of all points from every centroid\n",
    "  \n",
    "    return dist\n",
    "\n",
    "\n",
    "def sort_and_valuation(dist):\n",
    "    sorted_val = []\n",
    "    for each_centroid_list in dist:\n",
    "        each_centroid_list_sorted = sorted(each_centroid_list, key=lambda x: (x[A+1], x[0]))  # A+1 is index of type , 0 is dist\n",
    "        sorted_val.append(each_centroid_list_sorted)\n",
    "\n",
    "        # sort on basis of type & then dist.\n",
    "        # Now all whites are towards start and all black are after white as they have additional V added to their valuation\n",
    "        # Among the whites, the most closest is at start of list as it has more valuation.\n",
    "        # Similarly sort the black points among them based on distance as did with white\n",
    "\n",
    "    return sorted_val\n",
    "\n",
    "\n",
    "def clustering(sorted_valuation, hashmap_points,k_centroid,n,K):\n",
    "    n = n#len(hashmap_points.keys())  # total number of points in metric space\n",
    "    cluster_assign = []\n",
    "\n",
    "    for i in range(0, K):\n",
    "        cluster_assign.append([])  # initially all clusters are empty\n",
    "\n",
    "    tot_p_j =0 \n",
    "    curr_cluster =0\n",
    "    curr_j=0\n",
    "\n",
    "    curr_alloc_j= []\n",
    "    for j in range(0,J):\n",
    "        curr_alloc_j.append(0);\n",
    "\n",
    "    curr_alloc_j = np.array(curr_alloc_j)\n",
    "\n",
    "    tot_point_alloc_all_j = np.sum(np.floor(np.array(p_j)*K*n_j/100))\n",
    "    \n",
    "    print(\"Total points to allocate for current j are  :\"+str(tot_point_alloc_all_j))\n",
    "    \n",
    "    \n",
    "    while( tot_point_alloc_all_j !=  np.sum(curr_alloc_j)):\n",
    "        \n",
    "        j_tot_need = np.floor(K*p_j[curr_j]*n_j[j]/100)  #check how many points for j we need to assing in all to cluster\n",
    "\n",
    "      \n",
    "        \n",
    "        if curr_alloc_j[curr_j] == j_tot_need:   #curr alloc maintain for all k count of j \n",
    "            curr_j =(curr_j+1) % J\n",
    "            print(\"Working on J = J+1\")\n",
    "        \n",
    "                   \n",
    "        #print(\"Current j : \"+str(curr_j))\n",
    "        index=0\n",
    "        each = sorted_valuation[curr_cluster % K][index]\n",
    "\n",
    "        while each[-1] != curr_j:\n",
    "            index = index +1\n",
    "            each = sorted_valuation[curr_cluster % K][index]\n",
    "\n",
    "        #nowtotal_points_alloc_all_j find a non allocated point \n",
    "\n",
    "        while(index != len( sorted_valuation[curr_cluster % K] )):\n",
    "            \n",
    "            each = sorted_valuation[curr_cluster % K][index]\n",
    "            \n",
    "          \n",
    "            if tuple(each[1:]) in hashmap_points.keys():# each is (dist, X,Y,....Z, type)\n",
    "          \n",
    "                if int(hashmap_points[tuple(each[1: ])]) > 0:    #if some points of that type left to allocate\n",
    "                    cluster_assign[curr_cluster].append(each)\n",
    "                    hashmap_points[tuple(each[1: ])] -= 1\n",
    "                    curr_alloc_j[curr_j]+=1\n",
    "                    break\n",
    "                    \n",
    "            index = index +1 \n",
    "\n",
    "        curr_cluster = (curr_cluster+1)%K   \n",
    "        \n",
    "    print(\"Finding the left out points after allocation for p%\")\n",
    "    left_out_points = []\n",
    "\n",
    "  \n",
    "    for each in sorted_valuation[0]:           #check all points using any sorted val that whcih points are not allocated to any cluster using map dict. using sorted jsut need key for dict\n",
    "        if hashmap_points[tuple(each[1:])] > 0:  #if still unallocated point \n",
    "            left_out_points.append(each)                    #each is (dist, X,Y,....Z, type)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"Total left out points are \"+str(n-tot_point_alloc_all_j))\n",
    "    if len(left_out_points)>0:\n",
    "        left_out_points_= np.delete(left_out_points,0,1)  # colno , axis\n",
    "        left_out_points__= np.delete(left_out_points_,-1,1)  # colno , axis\n",
    "        distances_to_centroids_left_points = distance.cdist(left_out_points__, k_centroid, 'sqeuclidean')\n",
    "        cluster_assignment_left_points = np.argmin(distances_to_centroids_left_points, axis = 1)\n",
    "        ch =0\n",
    "        for ind in range(0,len(left_out_points)):\n",
    "            each = left_out_points[ind]\n",
    "            each_ = left_out_points_[ind]\n",
    "            each__ = left_out_points__[ind]\n",
    "            if int(hashmap_points[tuple(each[1:])]) > 0: \n",
    "                hashmap_points[tuple(each[1: ])] -= 1\n",
    "                cluster_assign[cluster_assignment_left_points[ind]].append(each)\n",
    "                ch = ch +1\n",
    "        print(\"Total points alloced  are:\"+str(ch+tot_point_alloc_all_j)) \n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "    check=0\n",
    "    for value in hashmap_points.values():\n",
    "        if  value >0:\n",
    "            check +=1\n",
    "    \n",
    "    print(\"Total points left  are:\"+str(check))\n",
    "    print(\"Total points in dataset are:\"+str(n))\n",
    "    \n",
    "    return cluster_assign\n",
    "\n",
    "\n",
    "def update_centroids(cluster_assign,K):\n",
    "\n",
    "    new_centroids = []\n",
    "    for k in range(0, K):\n",
    "\n",
    "        sum_a = []\n",
    "\n",
    "        for i in range(0, A):\n",
    "            sum_a.append(0)\n",
    "\n",
    "        for each in cluster_assign[k]:\n",
    "            sum_a = [sum(x) for x in zip(sum_a, each[1:-1])]\n",
    "            #each is (dist,X,Y,.....Z,type)\n",
    "      \n",
    "        new_coordinates = []\n",
    "        for a in range(0, A):\n",
    "            new_coordinates.append(sum_a[a] / len(cluster_assign[k]))\n",
    "        new_centroids.append(new_coordinates)\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "\n",
    "    return new_centroids\n",
    "\n",
    "\n",
    "\n",
    "def update_centroids_median(cluster_assign,K):\n",
    "    new_centroids = []\n",
    "    for k in range(0, K):\n",
    "\n",
    "        cAk =  np.array(cluster_assign[k])\n",
    "        cAk = np.delete(cAk,[0,-1],axis=1)\n",
    "      \n",
    "        if len(cAk) %2 ==0 and len(cAk)>0: \n",
    "            cc = [np.median(np.array(cAk[:-1])[:,cl]) for cl in range(0,cAk.shape[1])]\n",
    "            new_centroids.append(cc)\n",
    "        elif len(cAk) %2 !=0 and len(cAk)>0:\n",
    "            cc = [np.median(np.array(cAk)[:,cl]) for cl in range(0,cAk.shape[1])]\n",
    "            new_centroids.append(cc)\n",
    "        elif len(cAk)==0:\n",
    "            print(\"Error: No centroid found updation error\")\n",
    "    \n",
    "    return new_centroids\n",
    "        \n",
    "def calc_clustering_objective(k_centroid, cluster_assign,K):\n",
    "    cost = 0\n",
    "\n",
    "    for k in range(0, K):\n",
    "\n",
    "        for each in cluster_assign[k]:  #each is (dist, X,Y,....,Z,type)\n",
    "            dd = calc_distance_a(k_centroid[k], each[1:-1])\n",
    "            cost = cost + (dd)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PH2DWCeNOik"
   },
   "outputs": [],
   "source": [
    "def VanillaKmeans(X, k,seedValue):\n",
    "    \"\"\"\n",
    "    specify the number of clusters k and\n",
    "    the maximum iteration to run the algorithm\n",
    "    \"\"\"\n",
    "    n_row, n_col = X.shape\n",
    "    maxiter=100\n",
    "    \n",
    "    # randomly choose k data points as initial centroids\n",
    "    #if seed is not None:\n",
    "     #   np.random.seed(seed)\n",
    "    \n",
    "    rand_indices = np.random.choice(n_row, size = k)\n",
    "    centroids = X[rand_indices]\n",
    "    cost_variation=[]\n",
    "    cnt =0\n",
    "    for itr in range(maxiter):\n",
    "        # compute distances between each data point and the set of centroids\n",
    "        # and assign each data point to the closest centroid\n",
    "        distances_to_centroids = pairwise_distances(X, centroids, metric = 'sqeuclidean',force_all_finite=True)\n",
    "        cluster_assignment = np.argmin(distances_to_centroids, axis = 1)\n",
    "\n",
    "        # select all data points that belong to cluster i and compute\n",
    "        # the mean of these data points (each feature individually)\n",
    "        # this will be our new cluster centroids\n",
    "        new_centroids=[]\n",
    "        for i  in range(k):\n",
    "            #print(i)\n",
    "            assign= np.array([X[cluster_assignment == i]])\n",
    "            #print(assign)\n",
    "            med = np.mean(assign[0],axis=0)\n",
    "            new_centroids.append(med)             \n",
    "        #new_centroids = np.median( for i in range(k)]))\n",
    "        \n",
    "        # if the updated centroid is still the same,\n",
    "        # then the algorithm converged\n",
    "        new_centroids = np.array(new_centroids)\n",
    "       \n",
    "        if np.all(centroids == new_centroids):\n",
    "          \n",
    "                break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "        \n",
    "        heterogeneity = 0\n",
    "        for i in range(k):\n",
    "            # note that pairwise_distance only accepts 2d-array\n",
    "            cluster_data = X[cluster_assignment == i]\n",
    "            distances = pairwise_distances(cluster_data, [centroids[i]], metric = 'euclidean')\n",
    "            heterogeneity += np.sum(distances ** 2) #sq euclidean \n",
    "        cost_variation.append(heterogeneity)\n",
    "        \n",
    "    \n",
    "    return centroids, cluster_assignment, heterogeneity,cost_variation#(cost)\n",
    "\n",
    "def VanillaKmedian(X, k,seedValue):\n",
    "    \"\"\"\n",
    "    specify the number of clusters k and\n",
    "    the maximum iteration to run the algorithm\n",
    "    \"\"\"\n",
    "    n_row, n_col = X.shape\n",
    "    maxiter=100\n",
    "    \n",
    "    # randomly choose k data points as initial centroids\n",
    "    #if seed is not None:\n",
    "     #   np.random.seed(seed)\n",
    "    \n",
    "    rand_indices = np.random.choice(n_row, size = k)\n",
    "    centroids = X[rand_indices]\n",
    "    cost_variation=[]\n",
    "    cnt =0\n",
    "    for itr in range(maxiter):\n",
    "        # compute distances between each data point and the set of centroids\n",
    "        # and assign each data point to the closest centroid\n",
    "        distances_to_centroids = pairwise_distances(X, centroids, metric = 'sqeuclidean',force_all_finite=True)\n",
    "        cluster_assignment = np.argmin(distances_to_centroids, axis = 1)\n",
    "\n",
    "        # select all data points that belong to cluster i and compute\n",
    "        # the mean of these data points (each feature individually)\n",
    "        # this will be our new cluster centroids\n",
    "        new_centroids=[]\n",
    "        for i  in range(k):\n",
    "            #print(i)\n",
    "            assign= np.array([X[cluster_assignment == i]])\n",
    "            med = np.median(assign[0],axis=0)\n",
    "            new_centroids.append(med)             \n",
    "       \n",
    "        # if the updated centroid is still the same,\n",
    "        # then the algorithm converged\n",
    "        new_centroids = np.array(new_centroids)\n",
    "       \n",
    "        if np.all(centroids == new_centroids):\n",
    "    \n",
    "                break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "        \n",
    "        heterogeneity = 0\n",
    "        for i in range(k):\n",
    "            # note that pairwise_distance only accepts 2d-array\n",
    "            cluster_data = X[cluster_assignment == i]\n",
    "            distances = pairwise_distances(cluster_data, [centroids[i]], metric = 'euclidean')\n",
    "            heterogeneity += np.sum(distances ** 2) #sq euclidean \n",
    "        cost_variation.append(heterogeneity)\n",
    "        \n",
    "    \n",
    "    return centroids, cluster_assignment, heterogeneity,cost_variation#(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xp9EoBk_QKqE"
   },
   "outputs": [],
   "source": [
    "\n",
    "list_fair_run=[]\n",
    "list_obj_run =[]       \n",
    "list_balance_run=[]\n",
    "\n",
    "def main():\n",
    "    # Step1 : Load the dataset\n",
    "   \n",
    "    list_fair_K=[]\n",
    "    list_obj_K =[]       \n",
    "    list_balance_K=[]\n",
    "    \n",
    "    if(not os.path.isdir('Adult_tau_frac_OE')):\n",
    "        os.makedirs('Adult_tau_frac_OE')\n",
    "    for kk in [10]:#,2,5,15,20,30,40]:\n",
    "        K = kk\n",
    "        \n",
    "        print(\" K==\"+str(K)+\"  \")\n",
    "        \n",
    "        list_fair_run=[]\n",
    "        list_obj_run =[]       \n",
    "        list_balance_run=[]\n",
    "        list_time_run=[]\n",
    "        list_iterNo_run =[]\n",
    "        seeds = [0,100,200,300,400,500,600,700,800,900,1000,1100]\n",
    "      \n",
    "        for run in range(0,runs):\n",
    "            np.random.seed(seeds[run])\n",
    "            random.seed(seeds[run])\n",
    "            f = open('Adult_tau_frac_OE/K_'+str(K)+'_run_'+str(run)+'_output.txt', 'a')\n",
    "            print(\"+\"*100)\n",
    "            print('                        RUN  : '+ str(run))\n",
    "\n",
    "\n",
    "            list_fair_iter=[]\n",
    "            list_obj_iter =[]\n",
    "            list_balance_iter=[]\n",
    "\n",
    "   \n",
    "            # Step2 : Find initial K random centroids using k_random_index(df) & find_k_initial_centroid(df)\n",
    "            if option=='Kmeans':\n",
    "                k_centroid,_,_,_= VanillaKmeans(dfDropped.values,kk,seeds[run])\n",
    "            else:\n",
    "                 k_centroid,_,_,_= VanillaKmedian(dfDropped.values,kk,seeds[run])\n",
    "            prev_assignment =[]\n",
    "            cluster_assignment = []\n",
    "\n",
    "            for i in range(0, K):\n",
    "                cluster_assignment.append([])  # initially all clusters are empty\n",
    "\n",
    "            sum_time = 0\n",
    "            curr_itr = 0\n",
    "            prev_objective_cost=-1\n",
    "            objective_cost = 0\n",
    "            # Step3 : Find distances from the centroids using find_distances() with list of [ [x1,y1,z1..] , [x2,y2,z2..]....] centroids format list\n",
    "            while curr_itr <= iterations:# and prev_objective_cost != objective_cost:\n",
    "\n",
    "                start = timeit.default_timer()\n",
    "\n",
    "             \n",
    "\n",
    "               \n",
    "                df1 = df.values\n",
    "                k_centroids1= np.array(k_centroid)\n",
    "                dist = find_distances_fast(k_centroids1, df1)\n",
    "                \n",
    "               \n",
    "                valuation = sort_and_valuation(dist)\n",
    "                \n",
    "\n",
    "                #Step5 : Perform clustering using valuation matrix & hashmap of all points in metric\n",
    "                hash_map = {}\n",
    "            \n",
    "                for index, row in df.iterrows():\n",
    "                    temp = tuple(row[:-1])\n",
    "                    \n",
    "                    if tuple(row) in hash_map.keys():\n",
    "                       \n",
    "                        hash_map[tuple(row)] = int(hash_map[tuple(row)]) + 1\n",
    "                   \n",
    "                    else:\n",
    "                       \n",
    "                        hash_map.update({tuple(row): int(1)})   #dict is of form { (x,y): 0 , ....}\n",
    "            \n",
    "                \n",
    "                \n",
    "\n",
    "                prev_assignment = cluster_assignment\n",
    "                cluster_assignment = clustering(valuation, hash_map,k_centroid,len(dist[0]),K)\n",
    "\n",
    "                if option=='Kmeans':\n",
    "                \n",
    "                    k_centroid = update_centroids(cluster_assignment,K)\n",
    "                else:\n",
    "                    k_centroid = update_centroids_median(cluster_assignment,K)\n",
    "                    \n",
    "                clustering_cost = calc_clustering_objective(k_centroid,cluster_assignment,K)\n",
    "                if curr_itr!=0:\n",
    "                     prev_objective_cost = objective_cost\n",
    "                    \n",
    "                objective_cost = np.round(clustering_cost,3)\n",
    "\n",
    "\n",
    "               \n",
    "                list_obj_iter.append(str(objective_cost))\n",
    "                             #Step8 : Repeat from Step3 until clusters are same or iterations reach upper limit\n",
    "                stop = timeit.default_timer()\n",
    "                sum_time += (stop - start)\n",
    "             \n",
    "                curr_itr += 1\n",
    "\n",
    "              \n",
    "                print('-----------------------------Finished-----------------------------------------------\\n')\n",
    "\n",
    "        \n",
    "            list_time_run.append(sum_time)\n",
    "            list_iterNo_run.append(curr_itr-1)\n",
    "           \n",
    "            clustering_cost_converged = calc_clustering_objective(k_centroid,cluster_assignment,K)\n",
    "\n",
    "            print(\"\\nCost variation over iterations\")\n",
    "            print(list_obj_iter)\n",
    "            \n",
    "\n",
    "            f.close()\n",
    "            run  = run +1\n",
    "            list_obj_run.append(clustering_cost_converged)\n",
    "           \n",
    "        \n",
    "        print(\"@\"*70)\n",
    "        print(\"Cost variations over run\")\n",
    "        print(str(list_obj_run))\n",
    "       \n",
    "        print(\"Mean Cost variations over run\")\n",
    "        print(str(np.mean(np.array(list_obj_run))))\n",
    "        print(\"Std Dev Cost variations over run\")\n",
    "        print(str(np.std(np.array(list_obj_run))))\n",
    "        print(\"#\"*30)\n",
    "        print(\"Mean Time variation over run\")\n",
    "        print(str(np.mean(np.array(list_time_run))))\n",
    "        print(\"Std Dev time variation over run\")\n",
    "        print(str(np.std(np.array(list_time_run))))\n",
    "        print(\"#\"*30)\n",
    "        print(\"Mean iterations taken over run\")\n",
    "        print(str(np.mean(np.array(list_iterNo_run))))\n",
    "        print(\"Std Dev iteraions taken  over run\")\n",
    "        print(str(np.std(np.array(list_iterNo_run))))\n",
    "        print(\"#\"*30)\n",
    "        \n",
    "        list_obj_K.append(np.mean(np.array(list_obj_run)))\n",
    "       \n",
    "    print(\"%\"*70)\n",
    "    print(\"Cost variations over K\")\n",
    "    print(str(list_obj_K))\n",
    "\n",
    "    print(\"#\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LseQnmlvQKqI",
    "outputId": "a69bb294-b5c5-40ad-bbda-7afdcc5518c7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K==10  \n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 0\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['10400.359', '10410.031']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 1\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9859.086', '9855.732']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 2\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['10421.214', '10249.68']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 3\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9762.055', '9761.16']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 4\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9918.15', '9920.063']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 5\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9761.799', '9761.129']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 6\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9919.471', '9917.843']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 7\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['9761.48', '9760.727']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 8\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['10540.627', '10351.269']\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "                        RUN  : 9\n",
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total points to allocate for current j are  :26022.0\n",
      "Working on J = J+1\n",
      "Finding the left out points after allocation for p%\n",
      "Total left out points are 6539.0\n",
      "Total points alloced  are:32561.0\n",
      "Total points left  are:0\n",
      "Total points in dataset are:32561\n",
      "-----------------------------Finished-----------------------------------------------\n",
      "\n",
      "\n",
      "Cost variation over iterations\n",
      "['10149.344', '10130.18']\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Cost variations over run\n",
      "[10410.03061420457, 9855.731599495486, 10249.680340407196, 9761.16045799239, 9920.063429831376, 9761.129300861572, 9917.84261615937, 9760.726886973762, 10351.26896742746, 10130.180272163494]\n",
      "Mean Cost variations over run\n",
      "10011.781448551668\n",
      "Std Dev Cost variations over run\n",
      "239.73367830026183\n",
      "##############################\n",
      "Mean Time variation over run\n",
      "318.2062728322926\n",
      "Std Dev time variation over run\n",
      "8.645917940458856\n",
      "##############################\n",
      "Mean iterations taken over run\n",
      "1.0\n",
      "Std Dev iteraions taken  over run\n",
      "0.0\n",
      "##############################\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Cost variations over K\n",
      "[10011.781448551668]\n",
      "##############################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAT-t-Ibk7uB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tau-FRAC-OE_adult_0.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
